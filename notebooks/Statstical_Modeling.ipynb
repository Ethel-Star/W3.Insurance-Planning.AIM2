{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Academy: Artificial Intelligence Mastery\n",
    "#### Week 3 Challenge\n",
    "##### A/B_Hypothesis_Testing\n",
    "Ethel Cherotaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "data_dir=data_dir = r'E:\\2017.Study\\Tenx\\Week-3\\Data\\data'\n",
    "src_dir = r'E:\\2017.Study\\Tenx\\Week-3\\Insurance\\W3.Insurance-Planning.AIM2\\src'\n",
    "\n",
    "\n",
    "sys.path.append(src_dir)\n",
    "sys.path.append(data_dir)\n",
    "from Modeling_utils import InsuranceModeling \n",
    "from Feuture_utils  import InsuranceDataUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r'E:\\2017.Study\\Tenx\\Week-3\\Data\\data\\cleaned_data.csv'\n",
    "df = pd.read_csv(csv_file_path, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Processing \n",
    "Even though the data is already cleaned, let's double-check for any remaining missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "# Display columns with missing values and the count\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "Feature engineering: is the process of transforming raw data into relevant information for use by machine learning models. In other words, feature engineering is the process of creating predictive model features. A feature—also called a dimension—is an input variable used to generate model predictions. Because model performance largely rests on the quality of data used during training, feature engineering is a crucial preprocessing technique that requires selecting the most relevant aspects of raw training data for both the predictive task and model type under consideration.[1]\n",
    "\n",
    "New feature \n",
    "\n",
    "1. Extracting information from dates, such as the age of the vehicle from RegistrationYear.\n",
    "2. Binning SumInsured and cubiccapacity\n",
    "\n",
    "Converting continuous variables into categorical bins (e.g., \"Low,\" \"Medium,\" \"High\"). This can help models to understand different risk categories more easily.\n",
    "\n",
    "3. Extracting Information from TransactionMonth:\n",
    "\n",
    "features such as:\n",
    "\n",
    "Month: Helps identify seasonality.\n",
    "\n",
    "Quarter: Groups months into quarters.\n",
    "\n",
    "Year: Can be useful if the data spans multiple years.\n",
    "\n",
    "4.  Log-Transforming Skewed Features:\n",
    "\n",
    "Features like SumInsured and CalculatedPremiumPerTerm can be highly skewed. Applying a log transformation can normalize these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and preprocess\n",
    "utils = InsuranceDataUtils(df, target_column='TotalPremium')\n",
    "utils.add_date_features()\n",
    "utils.add_vehicle_age()\n",
    "utils.combine_province_zone()\n",
    "utils.apply_log_transformation()\n",
    "\n",
    "# Get the new dataset with only selected features\n",
    "selected_features_df = utils.get_selected_features_df()\n",
    "\n",
    "# Get the new dataset with only selected features\n",
    "selected_features_df = utils.get_selected_features_df()\n",
    "# List unique values in the 'Province' column\n",
    "selected_features_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing(encoding):\n",
    "\n",
    "Selected relevant features and preprocessed the data:\n",
    "1. Categorical Features: One-hot encoded.\n",
    "\n",
    "2. Numerical Features: Standard scaled.\n",
    "\n",
    "Created preprocessed DataFrames for analysis.\n",
    "\n",
    "#### Data Split \n",
    "The data was split for both the TotalClaims and TotalPremium variables. First, the process began by initializing the InsuranceDataUtils class with TotalClaims as the target variable, followed by feature preprocessing. The data was then divided into training and testing sets, and the shapes of these datasets were verified. Similarly, for TotalPremium, InsuranceDataUtils was initialized with TotalPremium as the target variable. The features were preprocessed, and the data was split into training and testing sets, with the shapes of the resulting datasets also confirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TotalPremium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with target column for TotalPremium\n",
    "encode_premium = InsuranceDataUtils(selected_features_df, target_column='TotalPremium')\n",
    "encode_premium.preprocess_features()\n",
    "encode_premium.split_data()\n",
    "preprocessed_df = encode_premium.get_preprocessed_df()\n",
    "\n",
    "preprocessed_df.head()\n",
    "# Initialize with target column for TotalClaims\n",
    "X_train_premium, X_test_premium, y_train_premium, y_test_premium = encode_premium.get_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TotalClaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_claims = InsuranceDataUtils(selected_features_df, target_column='TotalClaims')\n",
    "encode_claims.preprocess_features()\n",
    "encode_claims.split_data()\n",
    "preprocessed_df = encode_claims.get_preprocessed_df()\n",
    "\n",
    "preprocessed_df.head()\n",
    "# Print the shapes to verify\n",
    "X_train_claims, X_test_claims, y_train_claims, y_test_claims = encode_claims.get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data split for TotalPremium:\")\n",
    "print(\"Training set shape:\", encode_premium.X_train.shape)\n",
    "print(\"Testing set shape:\", encode_premium.X_test.shape)\n",
    "\n",
    "print(\"Data split for TotalClaims:\")\n",
    "print(\"Training set shape:\", encode_claims.X_train.shape)\n",
    "print(\"Testing set shape:\", encode_claims.X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling (Planned)\n",
    "\n",
    "Modeling Setup:\n",
    "    \n",
    "Planned to use,linear regression, DecisionTreeRegressor, RandomForestRegressor, and GradientBoostingRegressor to model the data for both TotalClaims and TotalPremium.\n",
    "\n",
    "Metrics:\n",
    "    \n",
    "Will evaluate models using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = InsuranceModeling(\n",
    "    X_train_premium, X_test_premium, y_train_premium, y_test_premium,\n",
    "    X_train_claims, X_test_claims, y_train_claims, y_test_claims\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.train_models()\n",
    "modeling.evaluate_models()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.feature_importance_analysis()\n",
    "modeling.shap_analysis('XGBoost')  # Replace with the desired model name\n",
    "modeling.lime_analysis('XGBoost')  # Replace with the desired model name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_path = r'E:\\2017.Study\\Tenx\\Week-3\\Data\\data\\cleaned_data.csv'\n",
    "# df = pd.read_csv(csv_file_path, low_memory=False)\n",
    "# utils = InsuranceDataUtils(df,'')\n",
    "\n",
    "# # Add features\n",
    "# utils.add_date_features()\n",
    "# utils.add_vehicle_age()\n",
    "# utils.combine_province_zone()\n",
    "# utils.apply_log_transformation()\n",
    "\n",
    "# # Get the new dataset with only selected features\n",
    "# selected_features_df = utils.get_selected_features_df()\n",
    "# # List unique values in the 'Province' column\n",
    "# selected_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode = InsuranceDataUtils(selected_features_df,target_column='TargetVariable')\n",
    "# encode.preprocess_features()\n",
    "# preprocessed_df = encode.get_preprocessed_df()\n",
    "\n",
    "# preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# csv_file_path = r'E:\\2017.Study\\Tenx\\Week-3\\Data\\data\\cleaned_data.csv'\n",
    "# df = pd.read_csv(csv_file_path, low_memory=False)\n",
    "\n",
    "# vehicle_features = InsuranceDataUtils(df)\n",
    "# df_with_age = vehicle_features.add_vehicle_age()\n",
    "# df_with_age_category = vehicle_features.add_vehicle_age_category()\n",
    "# df_encoded = vehicle_features.encode_vehicle_age_category()\n",
    "\n",
    "# print(df_encoded.head())\n",
    "# print(df_encoded.select_dtypes(include=['object']).columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = InsuranceDataUtils(df_encoded)\n",
    "# X_train_premium, X_test_premium, y_train_premium, y_test_premium = split.split_data('TotalPremium')\n",
    "\n",
    "# # Example usage for TotalClaims\n",
    "# X_train_claims, X_test_claims, y_train_claims, y_test_claims = split.split_data('TotalClaims')\n",
    "\n",
    "# print(\"Training and Testing sets created for both TotalPremium and TotalClaims.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insurance_modeling_premium = InsuranceModeling(df_encoded, 'TotalPremium')\n",
    "# insurance_modeling_premium.train_models()\n",
    "# evaluation_premium = insurance_modeling_premium.evaluate_models()\n",
    "# print(\"Evaluation results for TotalPremium:\")\n",
    "# for model_name, metrics in evaluation_premium.items():\n",
    "#     print(f\"{model_name}: {metrics}\")\n",
    "\n",
    "# # Model training and evaluation for TotalClaims\n",
    "# insurance_modeling_claims = InsuranceModeling(df_encoded, 'TotalClaims')\n",
    "# insurance_modeling_claims.train_models()\n",
    "# evaluation_claims = insurance_modeling_claims.evaluate_models()\n",
    "# print(\"Evaluation results for TotalClaims:\")\n",
    "# for model_name, metrics in evaluation_claims.items():\n",
    "#     print(f\"{model_name}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Series([ ], dtype: int64): indicates that there are no missing values in our dataset. The data is already cleaned on task-1 and there are no missing values to handle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
